# üìä An√°lise Completa: Sistema de Extra√ß√£o em Massa de Leads

## üìã Edge Functions Relacionadas √† Extra√ß√£o

### ‚úÖ Functions Baixadas (Backup Completo)

**Total de Functions Baixadas:** 36 functions

**Functions de Extra√ß√£o de Leads:** 12 functions principais

---

## üîß ARQUITETURA T√âCNICA DETALHADA

### **Sistema de Triggers SQL (Consolida√ß√£o Autom√°tica)**

O sistema usa **15 triggers SQL** na tabela `lead_extraction_staging` que executam automaticamente para consolidar dados de m√∫ltiplas fontes:

#### **1. Triggers BEFORE INSERT/UPDATE (Normaliza√ß√£o)**

**`trg_normalize_and_consolidate_staging_v2`** (BEFORE INSERT/UPDATE)
- **Fun√ß√£o:** `normalize_and_consolidate_staging_v2()`
- **Quando executa:** ANTES de inserir ou atualizar qualquer registro
- **O que faz:**
  - Extrai telefones de: `extracted_data->phones`, `whois_data->phones`, `cnpj_data->phones`
  - Extrai emails de: `extracted_data->emails`, `whois_data->emails`, `cnpj_data->emails`
  - Extrai websites de: `extracted_data->websites`, `whois_data->websites`, `cnpj_data->websites`
  - Chama `consolidate_all_phones()` para mesclar telefones sem duplicatas
  - Chama `consolidate_all_emails()` para mesclar emails sem duplicatas
  - Chama `consolidate_all_websites()` para mesclar websites sem duplicatas
  - Define `primary_phone`, `primary_email`, `primary_website` usando fun√ß√µes de prioriza√ß√£o
  - Consolida CNPJ de WHOIS e CNPJ API usando `consolidate_cnpj()`

#### **2. Triggers AFTER UPDATE (Enfileiramento e Migra√ß√£o)**

**`trg_auto_enqueue_scraping`** (AFTER INSERT/UPDATE)
- **Fun√ß√£o:** `trg_enqueue_scraping()`
- **Quando executa:** Ap√≥s inserir/atualizar com website
- **O que faz:** Enfileira website na fila `scraping_queue` para scraping

**`trg_update_run_metrics`** (AFTER INSERT)
- **Fun√ß√£o:** `update_run_completion()`
- **Quando executa:** Ap√≥s inserir novo lead
- **O que faz:** Atualiza m√©tricas do run (found_quantity, created_quantity)

**`trg_update_contact_type`** (BEFORE UPDATE)
- **Fun√ß√£o:** `update_contact_type_from_whatsapp()`
- **Quando executa:** Antes de atualizar com dados de WhatsApp
- **O que faz:** Define `contact_type` baseado em `whatsapp_valid`

**`trg_populate_phone_fields`** (AFTER UPDATE)
- **Fun√ß√£o:** `trg_populate_phone_fields()`
- **Quando executa:** Ap√≥s atualizar arrays de telefones
- **O que faz:** Atualiza campos legados (`phone_normalized`) para compatibilidade

**`trg_populate_email_fields`** (AFTER UPDATE)
- **Fun√ß√£o:** `trg_populate_email_fields()`
- **Quando executa:** Ap√≥s atualizar arrays de emails
- **O que faz:** Mant√©m sincroniza√ß√£o de campos legados

**`trg_populate_website_fields`** (AFTER UPDATE)
- **Fun√ß√£o:** `trg_populate_website_fields()`
- **Quando executa:** Ap√≥s atualizar arrays de websites
- **O que faz:** Atualiza campo `domain` para compatibilidade

**`trg_populate_cnpj_fields`** (AFTER UPDATE)
- **Fun√ß√£o:** `populate_cnpj_fields_on_migrate()`
- **Quando executa:** Ap√≥s migrar lead (`migrated_at` preenchido)
- **O que faz:** Popula campos personalizados do CNPJ na tabela `lead_custom_values`

**`trg_populate_whois_fields`** (AFTER UPDATE)
- **Fun√ß√£o:** `populate_whois_fields_on_migrate()`
- **Quando executa:** Ap√≥s migrar lead com dados WHOIS
- **O que faz:** Popula campos personalizados do WHOIS

**`trg_populate_contact_type`** (AFTER UPDATE)
- **Fun√ß√£o:** `populate_contact_type_on_migrate()`
- **Quando executa:** Ap√≥s migrar lead
- **O que faz:** Cria campo personalizado "Tipo de Contato" no Kanban

**`trg_sync_whatsapp_to_lead`** (AFTER UPDATE)
- **Fun√ß√£o:** `sync_whatsapp_staging_to_lead()`
- **Quando executa:** Ap√≥s atualizar dados de WhatsApp
- **O que faz:** Sincroniza `whatsapp_valid`, `whatsapp_jid`, `whatsapp_name` para tabela `leads`

**`trg_sync_custom_fields`** (AFTER UPDATE)
- **Fun√ß√£o:** `trg_sync_staging_to_custom_fields()`
- **Quando executa:** Ap√≥s atualizar dados enriquecidos
- **O que faz:** Sincroniza campos personalizados entre staging e leads

---

## üîÑ Fluxo Completo de Extra√ß√£o

### **FASE 1: Inicializa√ß√£o** üöÄ

#### 1. `start-extraction` (V4)
**Fun√ß√£o:** Inicia o processo de extra√ß√£o em massa

**Como funciona:**
- Recebe `run_id` da extra√ß√£o
- Busca configura√ß√£o da extra√ß√£o (termo de busca, localiza√ß√£o, quantidade alvo)
- Consulta hist√≥rico de p√°ginas j√° processadas (evita duplicatas)
- Calcula quantas p√°ginas do Google Maps precisa buscar
- Enfileira cada p√°gina na fila `google_maps_queue` com:
  - N√∫mero da p√°gina espec√≠fica
  - Termo de busca
  - Localiza√ß√£o
  - Workspace ID
  - Filtros (website, telefone, email, rating, reviews)
- Atualiza status do run para `running`
- Cria logs de progresso

**Caracter√≠sticas:**
- ‚úÖ Usa fila universal `google_maps_queue` para todos os workspaces
- ‚úÖ Respeita hist√≥rico (n√£o reprocessa p√°ginas j√° buscadas)
- ‚úÖ Suporta expans√£o de busca para todo o estado se necess√°rio
- ‚úÖ Versionamento: V4 (Fila Universal)

---

### **FASE 2: Busca no Google Maps** üìç

#### 2. `process-google-maps-queue` (V28)
**Fun√ß√£o:** Processa fila de p√°ginas do Google Maps em paralelo

**Como funciona:**
- L√™ at√© 5 mensagens da fila `google_maps_queue` por vez
- Processa em paralelo usando `Promise.allSettled`
- Para cada mensagem:
  - Chama `fetch-google-maps` com os dados da p√°gina
  - Deleta mensagem da fila ap√≥s sucesso
- Retorna resumo de processamento

**Caracter√≠sticas:**
- ‚úÖ Processamento paralelo (at√© 5 p√°ginas simult√¢neas)
- ‚úÖ Fila universal para todos os workspaces
- ‚úÖ Timeout de 30 segundos por mensagem
- ‚úÖ Versionamento: V28 (Fila Universal)

#### 3. `fetch-google-maps` (V14)
**Fun√ß√£o:** Busca dados de uma p√°gina espec√≠fica do Google Maps via SerpAPI

**Como funciona:**
- Recebe dados da p√°gina (n√∫mero, termo, localiza√ß√£o)
- Normaliza localiza√ß√£o para formato SerpAPI (ex: "S√£o Paulo, State of S√£o Paulo, Brazil")
- Seleciona API key rotativa (15 keys dispon√≠veis, distribui por p√°gina)
- Busca resultados do Google Maps via SerpAPI
- Valida resultados (deve ter: cid, title, address, latitude, longitude)
- Cria hash SHA256 para deduplica√ß√£o: `cid_title_address_lat_lng`
- Pr√©-filtra duplicatas em mem√≥ria (hashes existentes)
- Insere leads v√°lidos na tabela `lead_extraction_staging`
- Conta corretamente duplicatas (mem√≥ria + banco)
- Atualiza m√©tricas do run (found, created, duplicates, filtered)
- **Compensa√ß√£o autom√°tica:** Se √∫ltima p√°gina e < 90% do target:
  - Enfileira at√© 10 p√°ginas extras automaticamente
  - Continua at√© atingir meta ou esgotar API

**Caracter√≠sticas:**
- ‚úÖ Rota√ß√£o de 15 API keys (distribui carga)
- ‚úÖ Deduplica√ß√£o em 2 n√≠veis (mem√≥ria + banco)
- ‚úÖ Suporta expans√£o de busca para estado inteiro
- ‚úÖ Compensa√ß√£o autom√°tica se n√£o atingir meta
- ‚úÖ Detecta quando API esgota resultados
- ‚úÖ Versionamento: V14 (Fix contagem duplicatas)

**Dados extra√≠dos:**
- Nome do neg√≥cio
- Endere√ßo completo
- Coordenadas (lat/lng)
- Telefone (se dispon√≠vel)
- Email (se dispon√≠vel)
- Website (se dispon√≠vel)
- Rating e n√∫mero de reviews
- Categoria/Type
- Place ID do Google

---

### **FASE 3: Scraping Web** üåê

#### 4. `process-scraping-queue` (V6)
**Fun√ß√£o:** Processa fila de scraping de websites

**Como funciona:**
- L√™ mensagens da fila `scraping_queue`
- Controla concorr√™ncia m√°xima (10 simult√¢neos)
- Para cada lead com website:
  - Marca como `processing`
  - Chama API de scraping externa (proxy-scraper-api)
  - Extrai: emails, telefones, CNPJs, WhatsApp, redes sociais
  - Salva resultado via fun√ß√£o SQL `process_scraping_result`
  - Atualiza arrays de `phones`, `emails`, `websites`
  - Marca como `completed` ou `failed`
- Deleta mensagem da fila ap√≥s processar

**Caracter√≠sticas:**
- ‚úÖ Controle de concorr√™ncia (m√°x 10 simult√¢neos)
- ‚úÖ Timeout de 3 minutos por scraping
- ‚úÖ Retry autom√°tico em caso de falha
- ‚úÖ Extrai dados estruturados do website
- ‚úÖ Versionamento: V6 (Todas corre√ß√µes)

**Dados extra√≠dos do scraping:**
- Emails
- Telefones
- CNPJs
- WhatsApp
- Redes sociais (LinkedIn, Facebook, Instagram, etc)
- Metadados (title, description, og_image)
- Logos e favicons
- Bot√µes de checkout
- Pixels de rastreamento

---

### **FASE 4: Enriquecimento** üîç

#### 5. `enrich-orchestrator` (V1)
**Fun√ß√£o:** Orquestra todo o processo de enriquecimento de forma inteligente

**Como funciona:**
- **FASE 1 - WhatsApp:** Enriquece telefones normalizados
- **FASE 2 - WHOIS:** Enriquece dom√≠nios .br
- **FASE 3 - Extra√ß√£o CNPJ:** Extrai CNPJ dos dados WHOIS
- **FASE 4 - CNPJ:** Enriquece CNPJs normalizados
- Processa em lotes (batch_size configur√°vel)
- Aguarda delays entre fases (rate limits)

**Caracter√≠sticas:**
- ‚úÖ Orquestra√ß√£o inteligente de m√∫ltiplas fontes
- ‚úÖ Processa por workspace
- ‚úÖ Respeita rate limits das APIs
- ‚úÖ Consolida dados de m√∫ltiplas fontes

#### 6. `enrich-whatsapp` (V4)
**Fun√ß√£o:** Valida quais telefones t√™m WhatsApp

**Como funciona:**
- Busca leads com telefones n√£o validados
- Para cada telefone no array `phones`:
  - Valida se tem WhatsApp (chama API de valida√ß√£o)
  - Atualiza campo `whatsapp` no objeto do telefone
  - Determina tipo de contato (WhatsApp Ativo, Sem WhatsApp)
- Atualiza array completo de telefones
- Marca `whatsapp_valid` e `contact_type`

**Caracter√≠sticas:**
- ‚úÖ Processa arrays de telefones
- ‚úÖ Mant√©m outros telefones intactos
- ‚úÖ Rate limit: 1 request/segundo
- ‚úÖ Versionamento: V4 (Com arrays)

#### 7. `enrich-whois` (V5)
**Fun√ß√£o:** Enriquece dados de dom√≠nios .br via WHOIS

**Como funciona:**
- Busca leads com dom√≠nios .br n√£o enriquecidos
- Para cada dom√≠nio:
  - Consulta API WHOIS (Cloudflare Worker)
  - Extrai dados do registro
  - Salva em `whois_data`
  - Extrai CNPJ do WHOIS (se dispon√≠vel)
- Marca `whois_enriched = true`

**Caracter√≠sticas:**
- ‚úÖ Foca apenas em dom√≠nios .br
- ‚úÖ Extrai CNPJ automaticamente do WHOIS
- ‚úÖ Rate limit respeitado

#### 8. `enrich-cnpj` (V2)
**Fun√ß√£o:** Enriquece dados de empresas via CNPJ

**Como funciona:**
- Busca leads com CNPJ normalizado n√£o enriquecido
- Para cada CNPJ:
  - Tenta OpenCNPJ primeiro
  - Se falhar, tenta BrasilAPI
  - Extrai: raz√£o social, telefone, email, endere√ßo completo
  - Cria arrays de `phones` e `emails` do CNPJ
  - Salva em `cnpj_data`
  - Merge com arrays existentes (trigger SQL)
- Marca `cnpj_enriched = true`

**Caracter√≠sticas:**
- ‚úÖ Fallback entre APIs (OpenCNPJ ‚Üí BrasilAPI)
- ‚úÖ Merge inteligente de arrays
- ‚úÖ Rate limit: 3 segundos entre requests
- ‚úÖ Versionamento: V2 (Com merge de arrays)

#### 9. `process-cnpj-queue` (V5)
**Fun√ß√£o:** Processa fila de enriquecimento CNPJ

**Caracter√≠sticas:**
- Processa CNPJs em fila
- Controla rate limits

#### 10. `process-whois-queue` (V8)
**Fun√ß√£o:** Processa fila de enriquecimento WHOIS

**Caracter√≠sticas:**
- Processa dom√≠nios em fila
- Controla rate limits

#### 11. `process-whatsapp-queue` (V2)
**Fun√ß√£o:** Processa fila de valida√ß√£o WhatsApp

**Caracter√≠sticas:**
- Processa telefones em fila
- Valida WhatsApp em lote

---

### **FASE 5: Testes e Monitoramento** üß™

#### 12. `test-extraction-continuity` (V3)
**Fun√ß√£o:** Testa se extra√ß√£o continua da p√°gina correta

**Como funciona:**
- Chama `start-extraction` com run_id espec√≠fico
- Verifica se come√ßou da p√°gina correta (baseado no hist√≥rico)
- Retorna resultado do teste

**Caracter√≠sticas:**
- ‚úÖ Testa continuidade de extra√ß√µes
- ‚úÖ Valida hist√≥rico de p√°ginas

---

## üìä Estrutura de Dados

### Tabela Principal: `lead_extraction_staging`

**Campos importantes:**
- `extraction_run_id` - ID da execu√ß√£o
- `workspace_id` - Workspace do lead
- `client_name` - Nome do cliente
- `deduplication_hash` - Hash √∫nico para evitar duplicatas
- `status_extraction` - Status na extra√ß√£o (pending, google_fetched, scraped, ready)
- `status_enrichment` - Status no enriquecimento (pending, enriching, completed)
- `raw_google_data` - Dados brutos do Google Maps
- `raw_scraper_data` - Dados brutos do scraping
- `enrichment_data` - Dados consolidados de enriquecimento
- `phones` - Array de telefones: `[{number, source, type, verified, whatsapp}]`
- `emails` - Array de emails: `[{address, source, type, verified}]`
- `websites` - Array de websites: `[{url, type, source}]`
- `cnpj_normalized` - CNPJ normalizado (14 d√≠gitos)
- `cnpj_data` - Dados completos do CNPJ
- `whois_data` - Dados do WHOIS
- `whatsapp_valid` - Se tem WhatsApp
- `contact_type` - Tipo de contato (whatsapp, phone, unknown)
- `filter_passed` - Se passou nos filtros
- `should_migrate` - Se deve migrar para tabela `leads`

### Tabela de Controle: `lead_extraction_runs`

**Campos importantes:**
- `id` - ID √∫nico do run
- `extraction_id` - ID da configura√ß√£o de extra√ß√£o
- `workspace_id` - Workspace
- `status` - Status (pending, running, completed, failed)
- `target_quantity` - Quantidade alvo de leads
- `found_quantity` - Quantos o SerpAPI retornou
- `created_quantity` - Quantos foram realmente criados
- `duplicates_skipped` - Quantos duplicados foram pulados
- `filtered_out` - Quantos n√£o passaram nos filtros
- `pages_consumed` - Quantas p√°ginas foram consumidas
- `progress_data` - JSON com progresso detalhado
- `current_step` - Step atual do processo
- `completed_steps` - Steps completados
- `total_steps` - Total de steps (9)

### Tabela de Logs: `extraction_logs`

**Campos importantes:**
- `run_id` - ID do run
- `step_number` - N√∫mero do step (1-9)
- `step_name` - Nome do step
- `level` - N√≠vel (info, success, warning, error)
- `message` - Mensagem do log
- `details` - JSON com detalhes

---

## üîÑ Fluxo Completo (Passo a Passo)

```
1. USER cria extra√ß√£o ‚Üí lead_extractions
2. USER inicia extra√ß√£o ‚Üí cria lead_extraction_runs
3. USER chama start-extraction ‚Üí enfileira p√°ginas no google_maps_queue
4. CRON chama process-google-maps-queue ‚Üí processa fila
5. Para cada p√°gina ‚Üí chama fetch-google-maps
6. fetch-google-maps ‚Üí busca SerpAPI ‚Üí salva em lead_extraction_staging
7. TRIGGER SQL ‚Üí enfileira websites no scraping_queue
8. CRON chama process-scraping-queue ‚Üí faz scraping ‚Üí atualiza arrays
9. TRIGGER SQL ‚Üí enfileira telefones no whatsapp_validation_queue
10. CRON chama process-whatsapp-queue ‚Üí valida WhatsApp
11. TRIGGER SQL ‚Üí enfileira dom√≠nios .br no whois_queue
12. CRON chama process-whois-queue ‚Üí enriquece WHOIS ‚Üí extrai CNPJ
13. TRIGGER SQL ‚Üí enfileira CNPJs no cnpj_queue
14. CRON chama process-cnpj-queue ‚Üí enriquece CNPJ
15. TRIGGER SQL ‚Üí consolida todos os dados ‚Üí atualiza primary_phone, primary_email, primary_website
16. TRIGGER SQL ‚Üí aplica filtros ‚Üí marca filter_passed
17. TRIGGER SQL ‚Üí migra leads prontos para tabela leads
```

---

## üéØ Caracter√≠sticas Principais

### ‚úÖ Deduplica√ß√£o Inteligente
- Hash SHA256 baseado em: `cid_title_address_lat_lng`
- Pr√©-filtro em mem√≥ria (hashes existentes)
- Verifica√ß√£o no banco (constraint unique)
- Contagem precisa de duplicatas

### ‚úÖ Compensa√ß√£o Autom√°tica
- Se < 90% do target ap√≥s √∫ltima p√°gina
- Enfileira at√© 10 p√°ginas extras automaticamente
- Continua at√© atingir meta ou esgotar API

### ‚úÖ Enriquecimento Multi-Fonte
- Google Maps (dados b√°sicos)
- Scraping Web (emails, telefones, CNPJs)
- WhatsApp Validation (valida√ß√£o de contato)
- WHOIS (dados de dom√≠nio)
- CNPJ APIs (dados empresariais)

### ‚úÖ Consolida√ß√£o Inteligente
- Arrays de telefones, emails, websites
- Prioriza√ß√£o de fontes (CNPJ > WHOIS > Scraping > Google Maps)
- Campos prim√°rios (`primary_phone`, `primary_email`, `primary_website`)
- Merge autom√°tico via triggers SQL

### ‚úÖ Controle de Qualidade
- Filtros configur√°veis (website, telefone, email, rating, reviews)
- Valida√ß√£o de dados obrigat√≥rios
- Logs detalhados de cada step
- M√©tricas precisas (found, created, duplicates, filtered)

### ‚úÖ Escalabilidade
- Filas PGMQ para processamento ass√≠ncrono
- Processamento paralelo (at√© 5 p√°ginas simult√¢neas)
- Rota√ß√£o de API keys (15 keys dispon√≠veis)
- Controle de concorr√™ncia (scraping: 10 simult√¢neos)

---

## üìà M√©tricas e Monitoramento

### M√©tricas por Run:
- `found_quantity` - Quantos o SerpAPI retornou
- `created_quantity` - Quantos foram criados (sem duplicatas)
- `duplicates_skipped` - Quantos duplicados
- `filtered_out` - Quantos n√£o passaram nos filtros
- `pages_consumed` - Quantas p√°ginas foram usadas
- `credits_consumed` - Cr√©ditos SerpAPI consumidos
- `execution_time_ms` - Tempo total de execu√ß√£o

### Logs Detalhados:
- Step 1: Inicializa√ß√£o
- Step 2: Enfileiramento
- Step 3: Google Maps (por p√°gina)
- Step 4: Scraping
- Step 5: WhatsApp Validation
- Step 6: WHOIS Enrichment
- Step 7: CNPJ Extraction
- Step 8: CNPJ Enrichment
- Step 9: Finaliza√ß√£o

---

## üîß Configura√ß√µes Importantes

### Filtros de Extra√ß√£o:
- `require_website` - S√≥ leads com website
- `require_phone` - S√≥ leads com telefone
- `require_email` - S√≥ leads com email
- `min_rating` - Rating m√≠nimo
- `min_reviews` - M√≠nimo de reviews
- `expand_state_search` - Expande busca para todo estado

### Rate Limits:
- SerpAPI: Rota√ß√£o de 15 keys
- Scraping: M√°x 10 simult√¢neos
- WhatsApp: 1 request/segundo
- WHOIS: Delay de 2 segundos
- CNPJ: Delay de 3 segundos

---

## üî¨ DETALHES T√âCNICOS AVAN√áADOS

### **Fun√ß√µes SQL de Consolida√ß√£o**

#### **1. `consolidate_all_phones()`**
**Par√¢metros:** `phones_serpdev JSONB, phones_whois JSONB, phones_cnpj JSONB, phone_legacy TEXT`

**Processo:**
1. Itera sobre cada fonte de telefones (SerpDev, WHOIS, CNPJ)
2. Normaliza cada n√∫mero usando `normalize_phone()` (remove caracteres, valida formato BR)
3. Formata usando `format_phone_br()` (adiciona par√™nteses e h√≠fen)
4. Detecta tipo usando `detect_phone_type()` (mobile/landline)
5. Remove duplicatas usando array `seen_numbers`
6. Prioriza fontes: CNPJ (verified=true) > WHOIS > SerpDev
7. Retorna JSONB array com objetos: `{number, formatted, with_country, source, type, verified, whatsapp}`

**Tratamento de Erros:**
- Cada telefone √© processado em bloco `BEGIN...EXCEPTION`
- Erros s√£o logados via `log_error()` mas n√£o interrompem o processo
- Retorna array vazio em caso de erro catastr√≥fico

#### **2. `consolidate_all_emails()`**
**Par√¢metros:** `emails_serpdev JSONB, emails_whois JSONB, emails_cnpj JSONB`

**Processo:**
1. Valida formato com valida√ß√£o regex: `^[^@]+@[^@]+\.[^@]+$`
2. Normaliza para lowercase e trim
3. Remove duplicatas usando array `seen_emails`
4. Detecta tipo por prefixo: `contato*` ‚Üí contact, `vendas*` ‚Üí sales, `suporte*` ‚Üí support
5. Prioriza: CNPJ (verified=true) > WHOIS > SerpDev
6. Retorna JSONB array: `{address, source, type, verified}`

#### **3. `consolidate_all_websites()`**
**Par√¢metros:** `websites_serpdev JSONB, websites_whois JSONB, websites_cnpj JSONB, domain_legacy TEXT`

**Processo:**
1. Extrai dom√≠nio usando `extract_domain()` (remove protocolo, path, query)
2. Remove duplicatas por dom√≠nio usando array `seen_domains`
3. Detecta tipo: se URL cont√©m `instagram|facebook|linkedin|twitter` ‚Üí social, sen√£o ‚Üí main
4. Retorna JSONB array: `{url, domain, source, type}`

#### **4. Fun√ß√µes de Prioriza√ß√£o**

**`get_primary_phone(phones JSONB)`**
- Prioridade: WhatsApp + Verified > Verified + CNPJ > CNPJ > WHOIS > SerpDev > Mobile > Landline
- Retorna n√∫mero do telefone principal como TEXT

**`get_primary_email(emails JSONB)`**
- Prioridade: Verified + CNPJ > CNPJ > Sales/Contact > WHOIS > SerpDev
- Retorna endere√ßo do email principal como TEXT

**`get_primary_website(websites JSONB)`**
- Prioridade: Main + SerpDev > Main > Social
- Retorna URL do website principal como TEXT

### **Fun√ß√£o SQL de Processamento de Scraping**

#### **`process_scraping_result(p_staging_id UUID, p_scraping_data JSONB, p_status TEXT)`**

**Processo:**
1. Se `p_status = 'error'`: marca como `failed` e retorna false
2. Normaliza dados usando `normalize_scraping_data()`:
   - Converte telefones para formato padr√£o
   - Adiciona flag `whatsapp: true` para n√∫meros do WhatsApp
   - Normaliza emails (lowercase, trim)
   - Converte redes sociais para array de websites com `type: 'social'`
   - Extrai primeiro CNPJ se houver m√∫ltiplos
3. Faz merge com arrays existentes:
   - `phones`: UNION ALL + DISTINCT (remove duplicatas)
   - `emails`: UNION ALL + DISTINCT
   - `websites`: UNION ALL + DISTINCT
4. Atualiza `scraping_data` com metadados:
   - `checkouts`: `{have_checkouts, platforms}`
   - `pixels`: `{have_pixels, pixels}`
   - `performance`: m√©tricas de performance
5. Marca `scraping_enriched = true`, `scraping_status = 'completed'`
6. **Trigger `normalize_and_consolidate_staging_v2`** executa automaticamente ap√≥s UPDATE
7. Retorna `true` se sucesso, `false` se erro

### **Fun√ß√£o SQL de Migra√ß√£o**

#### **`migrate_leads_with_custom_values()`**

**Processo:**
1. Busca leads com `should_migrate = true` e `migrated_at IS NULL` (LIMIT 200)
2. Para cada lead:
   - Busca configura√ß√£o da extra√ß√£o (filtros)
   - **Aplica filtros:**
     - `require_email`: verifica se tem email em `emails` array OU `primary_email`
     - `require_phone`: verifica se tem telefone em `phones` array OU `primary_phone`
     - `require_website`: verifica se tem website em `websites` array OU `primary_website`
     - `min_rating`: compara com `extracted_data->rating`
     - `min_reviews`: compara com `extracted_data->reviews`
   - Se passa nos filtros:
     - Insere na tabela `leads` com `funnel_id` e `column_id` da extra√ß√£o
     - Popula campos personalizados (`custom_fields`) se existirem
     - Marca `migrated_at = NOW()`, `migrated_lead_id = new_lead_id`
   - Se n√£o passa:
     - Marca `should_migrate = false`, `filter_passed = false`, `filter_reason = 'sem_email,sem_telefone,...'`
3. Atualiza m√©tricas do run:
   - `filtered_out += v_filtered_count`
   - `created_quantity = COUNT(*) FROM leads WHERE lead_extraction_run_id = run_id`
4. Retorna n√∫mero de leads migrados

**Triggers ap√≥s migra√ß√£o:**
- `trg_populate_cnpj_fields`: popula campos CNPJ
- `trg_populate_whois_fields`: popula campos WHOIS
- `trg_populate_contact_type`: cria campo "Tipo de Contato"

### **Sistema de Filas PGMQ**

#### **Filas Utilizadas:**

1. **`google_maps_queue`** (Universal)
   - Mensagem: `{run_id, page, search_term, location, workspace_id, target_quantity, filters, is_last_page, is_compensation}`
   - Consumidor: `process-google-maps-queue`
   - Batch size: 5 mensagens por vez
   - VT (Visibility Timeout): 30 segundos

2. **`scraping_queue`**
   - Mensagem: `{staging_id, website_url}`
   - Consumidor: `process-scraping-queue`
   - Batch size: at√© 10 simult√¢neos (controle de concorr√™ncia)
   - VT: 180 segundos (3 minutos)

3. **`whatsapp_validation_queue`**
   - Mensagem: `{staging_id, phone_normalized}`
   - Consumidor: `process-whatsapp-queue`
   - Batch size: 30 por vez
   - VT: 60 segundos

4. **`whois_queue`**
   - Mensagem: `{staging_id, domain}`
   - Consumidor: `process-whois-queue`
   - Batch size: 10 por vez
   - VT: 120 segundos

5. **`cnpj_queue`**
   - Mensagem: `{lead_id, cnpj}`
   - Consumidor: `process-cnpj-queue`
   - Batch size: 10 por vez
   - VT: 120 segundos

### **Sistema de Deduplica√ß√£o**

#### **Hash SHA256**
- **Input:** `cid_title_address_lat_lng`
- **Exemplo:** `"1234567890_Empresa ABC_Rua XYZ, 123_-23.5505_-46.6333"`
- **Output:** Hash hexadecimal de 64 caracteres
- **Constraint:** `UNIQUE (workspace_id, deduplication_hash)`

#### **Pr√©-filtro em Mem√≥ria**
- `fetch-google-maps` busca todos os hashes existentes do workspace antes de inserir
- Cria `Set` em mem√≥ria para verifica√ß√£o O(1)
- Evita 90%+ das duplicatas antes de tentar INSERT

#### **Verifica√ß√£o no Banco**
- Se pr√©-filtro falhar, constraint UNIQUE captura duplicata
- C√≥digo de erro PostgreSQL: `23505` (unique_violation)
- Conta como `dbDuplicates` separadamente de `preFilterDuplicates`

### **Sistema de Compensa√ß√£o Autom√°tica**

#### **L√≥gica de Compensa√ß√£o:**
1. Executa apenas na **√∫ltima p√°gina** (`is_last_page = true`)
2. Aguarda 2 segundos para garantir que m√©tricas foram atualizadas
3. Calcula porcentagem: `(totalCreated / targetQuantity) * 100`
4. **Condi√ß√µes para compensar:**
   - `percentage < 90` (menos de 90% do target)
   - `compensationCount < MAX_COMPENSATION_PAGES` (m√°x 10 p√°ginas)
   - `!apiExhausted` (API ainda tem resultados)
5. Se compensar:
   - Calcula `leadsNeeded = targetQuantity - totalCreated`
   - Calcula `pagesNeeded = Math.ceil(leadsNeeded / 10)`
   - Limita a `MAX_COMPENSATION_PAGES - compensationCount`
   - Enfileira p√°ginas extras na fila `google_maps_queue_e4f9d774`
   - Marca `is_compensation = true` nas mensagens
6. Atualiza `progress_data.compensation_count` e `progress_data.compensation_pages_queued`

### **Rota√ß√£o de API Keys**

#### **Sistema de 15 API Keys:**
- Fun√ß√£o SQL: `get_serpdev_api_key(key_index INTEGER)`
- Sele√ß√£o: `keyIndex = ((page - 1) % 15) + 1`
- Distribui carga uniformemente entre as 15 keys
- Evita rate limits e esgotamento prematuro

### **Normaliza√ß√£o de Localiza√ß√£o**

#### **`normalizeLocationForSerper(location, expandState)`**

**Processo:**
1. Remove acentos usando `normalize('NFD').replace(/[\u0300-\u036f]/g, '')`
2. Divide por v√≠rgulas: `["Cidade", "Estado", "Pa√≠s"]`
3. Capitaliza palavras (exceto preposi√ß√µes: de, do, da, dos, das)
4. Mapeia estados brasileiros:
   - Abrevia√ß√µes: `"SP"` ‚Üí `"State of Sao Paulo"`
   - Nomes completos: `"S√£o Paulo"` ‚Üí `"State of Sao Paulo"`
5. Se `expandState = true`: retorna apenas `"State of {Estado}, Brazil"`
6. Formato final: `"Cidade, State of Estado, Brazil"`

**Exemplos:**
- `"S√£o Paulo, SP"` ‚Üí `"Sao Paulo, State of Sao Paulo, Brazil"`
- `"S√£o Paulo, SP"` (expandState=true) ‚Üí `"State of Sao Paulo, Brazil"`
- `"Rio de Janeiro, RJ"` ‚Üí `"Rio de Janeiro, State of Rio de Janeiro, Brazil"`

## üéì Conclus√£o

O sistema de extra√ß√£o √© **extremamente robusto** e bem arquitetado:

‚úÖ **Modular** - Cada fun√ß√£o tem responsabilidade √∫nica  
‚úÖ **Escal√°vel** - Filas PGMQ e processamento paralelo  
‚úÖ **Confi√°vel** - Deduplica√ß√£o em 2 n√≠veis, retry, compensa√ß√£o autom√°tica  
‚úÖ **Rastre√°vel** - Logs detalhados de cada step em `extraction_logs`  
‚úÖ **Inteligente** - Enriquecimento multi-fonte e consolida√ß√£o autom√°tica via triggers  
‚úÖ **Resiliente** - Tratamento de erros em cada n√≠vel (Edge Functions + SQL)  
‚úÖ **Perform√°tico** - Pr√©-filtro em mem√≥ria, batch processing, controle de concorr√™ncia  

**Total de Functions de Extra√ß√£o:** 12 functions principais  
**Total de Functions no Projeto:** 36 functions  
**Total de Triggers SQL:** 15 triggers  
**Total de Fun√ß√µes SQL de Consolida√ß√£o:** 20+ fun√ß√µes

