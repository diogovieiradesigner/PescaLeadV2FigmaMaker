# Deploy Manual da Edge Function Corrigida

## üéØ Corre√ß√µes Aplicadas

### 1. URL da API Atualizada
**Arquivo:** `supabase/functions/process-scraping-queue/index.ts`
**Linha 15:**
```typescript
// ‚ùå URL antiga (falhando)
const SCRAPER_API_URL = Deno.env.get('SCRAPER_API_URL') || 'https://proxy-scraper-api.diogo-vieira-pb-f91.workers.dev';

// ‚úÖ URL correta (funcionando)  
const SCRAPER_API_URL = Deno.env.get('SCRAPER_API_URL') || 'https://scraper.pescalead.com.br';
```

### 2. Fun√ß√£o de Sanitiza√ß√£o Completamente Atualizada
**Arquivo:** `supabase/functions/process-scraping-queue/index.ts`
**Fun√ß√£o `sanitizeScrapingData`:**

```typescript
function sanitizeScrapingData(data: any): ScrapingApiResponse {
  return {
    status: String(data.status || 'unknown'),
    url: String(data.url || ''),
    method: String(data.method || ''),
    emails: (data.emails || [])
      .map((e: any) => String(e))
      .filter((e: string) => e && e.includes('@')),
    phones: (data.phones || [])
      .map((p: any) => String(p).replace(/[^0-9+() -]/g, ''))
      .filter((p: string) => p && p.length >= 8),
    cnpj: (data.cnpj || [])
      .map((c: any) => validateCNPJ(String(c)))
      .filter(Boolean),
    whatsapp: (data.whatsapp || [])
      .map((w: any) => String(w)),
    social_media: {
      linkedin: (data.social_media?.linkedin || []).map((s: any) => String(s)),
      facebook: (data.social_media?.facebook || []).map((s: any) => String(s)),
      instagram: (data.social_media?.instagram || []).map((s: any) => String(s)),
      youtube: (data.social_media?.youtube || []).map((s: any) => String(s)),
      twitter: (data.social_media?.twitter || []).map((s: any) => String(s)),
    },
    metadata: {
      title: String(data.metadata?.title || ''),
      description: String(data.metadata?.description || ''),
      og_image: String(data.metadata?.og_image || ''),
    },
    images: {
      logos: (data.images?.logos || []).map((i: any) => String(i)),
      favicon: String(data.images?.favicon || ''),
      other_images: (data.images?.other_images || []).map((i: any) => String(i)),
    },
    button_links: (data.button_links || []).map((l: any) => String(l)),
    checkouts: {
      have_checkouts: Boolean(data.checkouts?.have_checkouts),
      platforms: (data.checkouts?.platforms || []).map((p: any) => String(p)),
    },
    pixels: {
      have_pixels: Boolean(data.pixels?.have_pixels),
      pixels: data.pixels?.pixels || {},
    },
    screenshot: {
      base64: '', // N√£o armazenar screenshot (muito grande)
      timestamp: String(data.screenshot?.timestamp || ''),
    },
    markdown: String(data.markdown || ''),
    performance: {
      total_time: String(data.performance?.total_time || '0s'),
    },
  };
}
```

## üöÄ Como Fazer o Deploy

### Op√ß√£o 1: Via Supabase CLI (Recomendado)

```bash
# 1. Navegar para o diret√≥rio do projeto
cd c:/Users/Asus/Pictures/Pesca lead - Back-end

# 2. Fazer o deploy da edge function
supabase functions deploy process-scraping-queue --project-ref nlbcwaxkeaddfocigwuk

# 3. Verificar se deploy foi bem-sucedido
supabase functions list --project-ref nlbcwaxkeaddfocigwuk
```

### Op√ß√£o 2: Via Dashboard Supabase

1. **Acesse o Dashboard:**
   ```
   https://supabase.com/dashboard/project/nlbcwaxkeaddfocigwuk
   ```

2. **Navegue para Edge Functions:**
   - Clique em "Edge Functions" no menu lateral
   - Ou acesse: https://supabase.com/dashboard/project/nlbcwaxkeaddfocigwuk/functions

3. **Encontre a fun√ß√£o:**
   - Procure por `process-scraping-queue`
   - Clique no nome da fun√ß√£o

4. **Deploy/Update:**
   - Clique em "Deploy" ou "Update"
   - Aguarde o processo de deploy (1-2 minutos)

### Op√ß√£o 3: Upload Manual dos Arquivos

**Se as op√ß√µes acima n√£o funcionarem:**

1. **Copie o conte√∫do do arquivo `index.ts`** (j√° corrigido)
2. **Cole no editor online do Supabase Dashboard**
3. **Salve e deploy**

## ‚úÖ Valida√ß√£o do Deploy

### 1. Teste R√°pido
```bash
curl -X POST "https://nlbcwaxkeaddfocigwuk.supabase.co/functions/v1/process-scraping-queue" \
  -H "Authorization: Bearer SUA_ANON_KEY" \
  -H "Content-Type: application/json"
```

### 2. Verificar nos Logs
```bash
# Ver logs da edge function
supabase functions logs process-scraping-queue --project-ref nlbcwaxkeaddfocigwuk
```

### 3. Testar na Interface
1. Acesse: http://localhost:3000/extracao/progresso/3c7a7725-b38b-40a4-8dba-569f22002946
2. V√° para aba "Scraping"
3. Verifique se aparecem novos logs

## üìä O Que Esperar Ap√≥s o Deploy

### Logs na Interface
```
[15:30] üåê [SCRAPE] Calling scraper API: https://scraper.pescalead.com.br
[15:30] üìç [TARGET] Website: https://example.com
[15:32] ‚ö° [RESPONSE] Got response in 2.1s, status: 200
[15:32] üìä [DATA] Scraping completed with status: success
[15:32] üìß [EMAILS] Found 2 emails
[15:32] üì± [PHONES] Found 1 phones
[15:32] üåê [SOCIAL] FB:0 IG:0
[15:32] ‚úÖ [SAVED] Result saved to database
```

### Dados no Banco
```sql
-- Verificar dados completos salvos
SELECT 
  username,
  website_scraping_status,
  website_scraping_data->'emails' as emails,
  website_scraping_data->'whatsapp' as whatsapp,
  website_scraping_data->'markdown' as markdown_length
FROM instagram_enriched_profiles 
WHERE run_id = '3c7a7725-b38b-40a4-8dba-569f22002946'::UUID
  AND website_scraping_status = 'completed';
```

## üîç Principais Mudan√ßas Implementadas

### ‚úÖ URL da API Correta
- **Antes:** `https://proxy-scraper-api.diogo-vieira-pb-f91.workers.dev` (falhando)
- **Depois:** `https://scraper.pescalead.com.br` (funcionando)

### ‚úÖ Dados Completos (Sem Truncamento)
- **Emails:** Todos os emails (sem limite de 100)
- **Telefones:** Todos os telefones (sem limite de 100)  
- **WhatsApp:** Todos os links (sem limite)
- **Markdown:** Conte√∫do completo (sem limite de 50k chars)
- **Links:** Todos os button_links (sem limite de 50)
- **Social Media:** Todas as redes (sem limite de 20)
- **Imagens:** Todas as URLs (sem limite)
- **Metadata:** Title e description completos

### ‚úÖ Tratamento da Resposta
- **Sanitiza√ß√£o inteligente:** Remove apenas dados inv√°lidos
- **Preserva√ß√£o total:** Mant√©m todos os dados v√°lidos
- **Estrutura completa:** Todos os campos da API s√£o salvos

## üéØ Resumo

**Problema:** Edge function usando URL antiga e truncando dados
**Solu√ß√£o:** URL atualizada + fun√ß√£o de sanitiza√ß√£o permissiva
**Resultado:** Todos os dados da API s√£o salvos completos

**Ap√≥s o deploy, voc√™ ver√°:**
- ‚úÖ Scraping funcionando com nova API
- ‚úÖ Todos os dados preservados (emails, phones, whatsapp, etc.)
- ‚úÖ Logs completos na interface
- ‚úÖ Conte√∫do markdown integral
- ‚úÖ Todos os links e CTAs salvos

**Pr√≥ximo passo:** Fazer o deploy e testar!